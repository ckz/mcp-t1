{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Content MCP Demo\n",
    "\n",
    "This notebook demonstrates how to use the Web Content MCP server with AutoGen to create a workflow that:\n",
    "\n",
    "1. Fetches web content from a URL\n",
    "2. Rewrites the content in a tech news style\n",
    "3. Optionally writes the rewritten content to a file\n",
    "\n",
    "The Web Content MCP server provides a tool for fetching content from web pages, which can then be processed by AutoGen agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before running the examples, make sure you have:\n",
    "\n",
    "1. Installed the required dependencies:\n",
    "   ```\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "2. Built the TypeScript MCP server:\n",
    "   ```\n",
    "   npm install\n",
    "   npm run build\n",
    "   ```\n",
    "\n",
    "3. Created a `.env` file with your OpenAI API key:\n",
    "   ```\n",
    "   OPENAI_API_KEY=your_openai_api_key_here\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import common libraries used across all examples\n",
    "import asyncio\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.tools.mcp import StdioServerParams, mcp_server_tools\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if OpenAI API key is set\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"⚠️ Warning: OPENAI_API_KEY not set in .env file\")\n",
    "    \n",
    "# Helper function to truncate content to avoid context length issues\n",
    "def truncate_content(content, max_chars=5000):\n",
    "    \"\"\"Truncate content to avoid context length issues\"\"\"\n",
    "    if len(content) > max_chars:\n",
    "        return content[:max_chars] + \"\\n\\n[Content truncated due to length...]\\n\"\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Fetch and Rewrite\n",
    "\n",
    "This example demonstrates the basic workflow:\n",
    "1. Set up the MCP fetch server\n",
    "2. Create two agents: one for fetching content and one for rewriting it\n",
    "3. Run the workflow to fetch and rewrite content from a URL\n",
    "\n",
    "The workflow uses a round-robin approach where agents take turns processing the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def example1():\n",
    "    # Setup the MCP fetch server parameters\n",
    "    fetch_mcp_server = StdioServerParams(command=\"node\", args=[\"./build/index.js\"])\n",
    "    \n",
    "    # Get the fetch tool from the MCP server\n",
    "    tools = await mcp_server_tools(fetch_mcp_server)\n",
    "    \n",
    "    # Create fetch agent with the MCP fetch tool\n",
    "    fetch_agent = AssistantAgent(\n",
    "        name=\"content_fetcher\",\n",
    "        model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "        tools=tools,  # The MCP fetch tool will be included here\n",
    "        system_message=\"\"\"You are a web content retrieval assistant. Use the fetch tool to get web content.\n",
    "        \n",
    "        IMPORTANT INSTRUCTIONS TO AVOID CONTEXT LENGTH ISSUES:\n",
    "        1. Only fetch a very small amount of content - no more than a few paragraphs\n",
    "        2. After fetching, extract only the title and first 2-3 paragraphs\n",
    "        3. Summarize the content in 1-2 short paragraphs before passing it to the rewriter\n",
    "        4. Do not include the entire webpage content in your response\n",
    "        5. Keep your response under 1000 words total\n",
    "        \n",
    "        If the content is still too large, truncate it further before passing to the rewriter.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Create rewriter Agent\n",
    "    rewriter_agent = AssistantAgent(\n",
    "        name=\"content_rewriter\",\n",
    "        model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "        system_message=\"\"\"You are a content rewriting expert. Rewrite the web content provided to you in a tech news style.\n",
    "        Tech news style characteristics:\n",
    "        1. Concise, attention-grabbing headline\n",
    "        2. Direct opening that states the main point\n",
    "        3. Objective but engaging content\n",
    "        4. Use of technical terms with clear explanations\n",
    "        5. Short paragraphs with emphasized key points\n",
    "        \n",
    "        Keep your rewrite very concise - no more than 300 words total.\n",
    "        When you complete the rewrite, reply with TERMINATE.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Set up termination condition and team\n",
    "    termination = TextMentionTermination(\"TERMINATE\")\n",
    "    team = RoundRobinGroupChat([fetch_agent, rewriter_agent], termination_condition=termination)\n",
    "    \n",
    "    # Run the workflow with a very small article URL\n",
    "    result = await team.run(\n",
    "        task=\"Fetch content from https://example.com and rewrite it in a tech news style\",\n",
    "        cancellation_token=CancellationToken()\n",
    "    )\n",
    "    \n",
    "    print(\"\\nFinal rewritten content:\\n\")\n",
    "    print(result.messages[-1].content)\n",
    "    return result\n",
    "\n",
    "# Run Example 1\n",
    "# Uncomment the line below to run this example\n",
    "# await example1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: With UI Console\n",
    "\n",
    "This example builds on Example 1 by adding a UI console to display the conversation between agents. This makes it easier to follow the workflow and understand how the agents interact with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "async def example2():\n",
    "    # Setup the MCP fetch server parameters\n",
    "    fetch_mcp_server = StdioServerParams(command=\"node\", args=[\"./build/index.js\"])\n",
    "    \n",
    "    # Get the fetch tool from the MCP server\n",
    "    tools = await mcp_server_tools(fetch_mcp_server)\n",
    "    \n",
    "    # Create fetch agent with the MCP fetch tool\n",
    "    fetch_agent = AssistantAgent(\n",
    "        name=\"content_fetcher\",\n",
    "        model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),  # Using mini model to reduce token usage\n",
    "        tools=tools,\n",
    "        system_message=\"\"\"You are a web content retrieval assistant. Use the fetch tool to get web content.\n",
    "        \n",
    "        IMPORTANT INSTRUCTIONS TO AVOID CONTEXT LENGTH ISSUES:\n",
    "        1. Only fetch a very small amount of content - no more than a few paragraphs\n",
    "        2. After fetching, extract only the title and first 2-3 paragraphs\n",
    "        3. Summarize the content in 1-2 short paragraphs before passing it to the rewriter\n",
    "        4. Do not include the entire webpage content in your response\n",
    "        5. Keep your response under 1000 words total\n",
    "        \n",
    "        If the content is still too large, truncate it further before passing to the rewriter.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Create rewriter Agent\n",
    "    rewriter_agent = AssistantAgent(\n",
    "        name=\"content_rewriter\",\n",
    "        model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),  # Using mini model to reduce token usage\n",
    "        system_message=\"\"\"You are a content rewriting expert. Rewrite the web content provided to you in a tech news style.\n",
    "        Tech news style characteristics:\n",
    "        1. Concise, attention-grabbing headline\n",
    "        2. Direct opening that states the main point\n",
    "        3. Objective but engaging content\n",
    "        4. Use of technical terms with clear explanations\n",
    "        5. Short paragraphs with emphasized key points\n",
    "        \n",
    "        Keep your rewrite very concise - no more than 300 words total.\n",
    "        When you complete the rewrite, reply with TERMINATE.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Set up termination condition and team\n",
    "    termination = TextMentionTermination(\"TERMINATE\")\n",
    "    team = RoundRobinGroupChat([fetch_agent, rewriter_agent], termination_condition=termination)\n",
    "    \n",
    "    # Use a very small website\n",
    "    task = \"Fetch content from https://example.org and rewrite it in a tech news style\"\n",
    "    \n",
    "    # Display the conversation process\n",
    "    stream = team.run_stream(task=task, cancellation_token=CancellationToken())\n",
    "    await Console(stream)\n",
    "    \n",
    "    # Get the final result (using a separate run call)\n",
    "    result = await team.run(task=task, cancellation_token=CancellationToken())\n",
    "    \n",
    "    print(\"\\nFinal rewritten content:\\n\")\n",
    "    print(result.messages[-1].content)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run Example 2\n",
    "# Uncomment the line below to run this example\n",
    "# await example2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: With File Writing\n",
    "\n",
    "This example extends the workflow by adding a third agent that writes the rewritten content to a file. It demonstrates how to use multiple MCP servers together (the custom fetch server and the standard filesystem server)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "async def example3():\n",
    "    # Setup the MCP fetch server parameters\n",
    "    # This server is used to fetch web content\n",
    "    fetch_mcp_server = StdioServerParams(command=\"node\", args=[\"./build/index.js\"])\n",
    "\n",
    "    # Setup the MCP filesystem server parameters\n",
    "    # This server is used to write to local files\n",
    "    write_mcp_server = StdioServerParams(command=\"npx\", args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", \".\"])\n",
    "    \n",
    "    # Get the fetch tool from the MCP server\n",
    "    tools_fetch = await mcp_server_tools(fetch_mcp_server)\n",
    "\n",
    "    # Get the filesystem tool from the MCP server\n",
    "    tools_write = await mcp_server_tools(write_mcp_server)\n",
    "    \n",
    "    # Create content fetcher agent\n",
    "    # This agent is responsible for fetching web content\n",
    "    fetch_agent = AssistantAgent(\n",
    "        name=\"content_fetcher\",\n",
    "        model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "        tools=tools_fetch,\n",
    "        system_message=\"\"\"You are a web content retrieval assistant. Use the fetch tool to get web content.\n",
    "        \n",
    "        IMPORTANT INSTRUCTIONS TO AVOID CONTEXT LENGTH ISSUES:\n",
    "        1. Only fetch a very small amount of content - no more than a few paragraphs\n",
    "        2. After fetching, extract only the title and first 2-3 paragraphs\n",
    "        3. Summarize the content in 1-2 short paragraphs before passing it to the rewriter\n",
    "        4. Do not include the entire webpage content in your response\n",
    "        5. Keep your response under 1000 words total\n",
    "        \n",
    "        If the content is still too large, truncate it further before passing to the rewriter.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Create content rewriter agent\n",
    "    # This agent is responsible for rewriting web content in tech news style\n",
    "    # Note: No longer adding TERMINATE at completion, but passing content to the next agent    \n",
    "    rewriter_agent = AssistantAgent(\n",
    "        name=\"content_rewriter\",\n",
    "        model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "        system_message=\"\"\"You are a content rewriting expert. Rewrite the web content provided to you in a tech news style.\n",
    "        Tech news style characteristics:\n",
    "        1. Concise, attention-grabbing headline\n",
    "        2. Direct opening that states the main point\n",
    "        3. Objective but engaging content\n",
    "        4. Use of technical terms with clear explanations\n",
    "        5. Short paragraphs with emphasized key points\n",
    "        \n",
    "        Keep your rewrite very concise - no more than 300 words total.\n",
    "        When you complete the rewrite, pass the content to the content_writer agent to save it to a file.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Get current date and format as YYYY-MM-DD\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Create file writer agent\n",
    "    # This agent is responsible for writing the rewritten content to a local file\n",
    "    # Note: This agent will add TERMINATE after completing its task to end the conversation\n",
    "    write_agent = AssistantAgent(\n",
    "        name=\"content_writer\",\n",
    "        model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "        tools=tools_write,\n",
    "        system_message=f\"\"\"You are a file assistant. Use the filesystem tool to write the content provided by content_rewriter to a text file named with today's date ({current_date}.txt).\n",
    "        When you successfully write the file, reply with \"TERMINATE\" to end the conversation.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Set up termination condition and team\n",
    "    # When any agent replies with TERMINATE, the conversation will end\n",
    "    termination = TextMentionTermination(\"TERMINATE\")\n",
    "    team = RoundRobinGroupChat([fetch_agent, rewriter_agent, write_agent], termination_condition=termination)\n",
    "    \n",
    "    # Use a very small website\n",
    "    task = \"Fetch content from https://example.com, rewrite it in a tech news style, and save the rewritten article to a local text file\"\n",
    "    \n",
    "    # Execute the task once using the run method\n",
    "    result = await team.run(task=task, cancellation_token=CancellationToken())\n",
    "    \n",
    "    # Print the final result\n",
    "    print(f\"\\nFile has been written to {current_date}.txt\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run Example 3\n",
    "# Uncomment the line below to run this example\n",
    "# await example3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Examples\n",
    "\n",
    "To run any of the examples, uncomment the corresponding await line at the end of each example function. For instance, to run Example 1, uncomment the line `# await example1()`.\n",
    "\n",
    "You can run the examples one at a time to see how each works. Below is a simple way to run Example 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Example 1 (Basic fetch and rewrite)\n",
    "# This uses example.com which is a very small website to avoid context length issues\n",
    "await example1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated three examples of using the Web Content MCP server with AutoGen:\n",
    "\n",
    "1. **Basic Example**: Fetching and rewriting web content\n",
    "2. **UI Console Example**: Adding a UI to visualize the conversation between agents\n",
    "3. **File Writing Example**: Extending the workflow to save the rewritten content to a file\n",
    "\n",
    "These examples showcase how MCP servers can be used to extend the capabilities of AutoGen agents, allowing them to interact with external systems like web content and the filesystem.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **MCP Servers**: Provide tools that agents can use to interact with external systems\n",
    "- **AutoGen Agents**: Specialized AI assistants that can use tools and communicate with each other\n",
    "- **Round-Robin Teams**: A way to organize agents to take turns processing a task\n",
    "- **Termination Conditions**: Rules that determine when a conversation should end\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "You can extend these examples by:\n",
    "- Adding more agents to the workflow\n",
    "- Implementing different conversation patterns\n",
    "- Creating custom MCP servers for other external systems\n",
    "- Building a web UI for the workflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
