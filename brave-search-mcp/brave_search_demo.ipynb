{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brave Search MCP Server and Client Demo\n",
    "\n",
    "This notebook demonstrates how to use the Brave Search MCP server and clients in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "First, let's install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install langchain langchain_openai autogen requests flask python-dotenv ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up Environment Variables\n",
    "\n",
    "Create a `.env` file with your API keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%writefile .env\n",
    "# API Keys for MCP Server and Client\n",
    "BRAVE_SEARCH_API_KEY=your_brave_search_api_key_here\n",
    "OPENAI_API_KEY=your_openai_api_key_here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Start the MCP Server\n",
    "\n",
    "Now let's start the MCP server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import threading\n",
    "import time\n",
    "import requests\n",
    "from flask import Flask, request, jsonify\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment variables\n",
    "BRAVE_SEARCH_API_KEY = os.getenv(\"BRAVE_SEARCH_API_KEY\")\n",
    "if not BRAVE_SEARCH_API_KEY or BRAVE_SEARCH_API_KEY == \"your_brave_search_api_key_here\":\n",
    "    print(\"⚠️ Warning: BRAVE_SEARCH_API_KEY not properly set in .env file\")\n",
    "\n",
    "BRAVE_SEARCH_ENDPOINT = \"https://api.search.brave.com/res/v1/web/search\"\n",
    "\n",
    "# Create a Flask server\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Add a basic route for testing\n",
    "@app.route('/', methods=['GET'])\n",
    "def hello():\n",
    "    return jsonify({\"status\": \"MCP server is running\"}), 200\n",
    "\n",
    "@app.route('/search', methods=['POST'])\n",
    "def search():\n",
    "    data = request.json\n",
    "    query = data.get('query', '')\n",
    "    count = data.get('count', 5)\n",
    "\n",
    "    # Call the actual Brave Search API\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"X-Subscription-Token\": BRAVE_SEARCH_API_KEY\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"count\": count\n",
    "    }\n",
    "\n",
    "    response = requests.get(BRAVE_SEARCH_ENDPOINT, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Process the response to match our expected format\n",
    "        results = response.json()\n",
    "        processed_results = {\n",
    "            \"results\": [\n",
    "                {\n",
    "                    \"title\": item.get(\"title\", \"\"),\n",
    "                    \"url\": item.get(\"url\", \"\"),\n",
    "                    \"description\": item.get(\"description\", \"\")\n",
    "                }\n",
    "                for item in results.get(\"web\", {}).get(\"results\", [])\n",
    "            ]\n",
    "        }\n",
    "        return jsonify(processed_results)\n",
    "    else:\n",
    "        return jsonify({\"error\": f\"Error: {response.status_code} - {response.text}\"}), 500\n",
    "\n",
    "# Function to run the Flask server in a separate thread\n",
    "def run_flask_server():\n",
    "    app.run(host='127.0.0.1', port=8080, debug=False, use_reloader=False)\n",
    "\n",
    "# Start the server in a background thread\n",
    "server_thread = threading.Thread(target=run_flask_server)\n",
    "server_thread.daemon = True\n",
    "server_thread.start()\n",
    "\n",
    "# Give the server time to start\n",
    "print(\"Starting MCP server...\")\n",
    "time.sleep(5)  # Increased wait time\n",
    "print(\"MCP Server is now running at http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the Server\n",
    "\n",
    "Let's test the server to make sure it's working correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test direct API calls to confirm server is working\n",
    "print(\"Testing direct API calls to the MCP server...\")\n",
    "\n",
    "# First, test the root endpoint\n",
    "try:\n",
    "    root_response = requests.get(\"http://127.0.0.1:8080/\")\n",
    "    print(f\"Root endpoint test - Status: {root_response.status_code}\")\n",
    "    if root_response.status_code == 200:\n",
    "        print(\"Root endpoint is working!\")\n",
    "    else:\n",
    "        print(f\"Root endpoint error: {root_response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection error to root endpoint: {str(e)}\")\n",
    "\n",
    "# Then, test the search endpoint\n",
    "try:\n",
    "    search_response = requests.post(\n",
    "        \"http://127.0.0.1:8080/search\",\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        json={\"query\": \"test query\", \"count\": 1}\n",
    "    )\n",
    "    print(f\"Search endpoint test - Status: {search_response.status_code}\")\n",
    "    if search_response.status_code == 200:\n",
    "        print(\"Search endpoint is working correctly!\")\n",
    "        print(f\"Response preview: {str(search_response.json())[:200]}...\")\n",
    "    else:\n",
    "        print(f\"Search endpoint error: {search_response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection error to search endpoint: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LangChain Client Implementation\n",
    "\n",
    "Now let's implement the LangChain client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "\n",
    "def brave_search(query):\n",
    "    \"\"\"Use Brave Search to find information on the web via local MCP server.\"\"\"\n",
    "    url = \"http://127.0.0.1:8080/search\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\"query\": query, \"count\": 5}\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results.get(\"results\", [])):\n",
    "            formatted_results.append(f\"{i+1}. {result.get('title')}: {result.get('url')}\\n{result.get('description')}\\n\")\n",
    "        return \"\\n\".join(formatted_results)\n",
    "    else:\n",
    "        return f\"Error: {response.status_code} - {response.text}\"\n",
    "\n",
    "def run_langchain_demo(query):\n",
    "    # Create a LangChain tool\n",
    "    brave_tool = Tool(\n",
    "        name=\"BraveSearch\",\n",
    "        description=\"Useful for searching the web about current events, data, or any information you need to answer questions.\",\n",
    "        func=brave_search\n",
    "    )\n",
    "\n",
    "    # Initialize the LLM with API key from .env\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key or openai_api_key == \"your_openai_api_key_here\":\n",
    "        print(\"⚠️ Warning: OPENAI_API_KEY not properly set in .env file\")\n",
    "\n",
    "    llm = ChatOpenAI(api_key=openai_api_key, temperature=0)\n",
    "\n",
    "    # Initialize the agent with the Brave Search tool\n",
    "    agent = initialize_agent(\n",
    "        [brave_tool],\n",
    "        llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    return agent.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. AutoGen Client Implementation\n",
    "\n",
    "Now let's implement the AutoGen client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import autogen\n",
    "\n",
    "# Define the function to query the local MCP server\n",
    "def query_brave_search(query):\n",
    "    \"\"\"Query the local Brave Search MCP server.\"\"\"\n",
    "    url = \"http://127.0.0.1:8080/search\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\"query\": query, \"count\": 5}\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code} - {response.text}\"\n",
    "\n",
    "def run_autogen_demo(query):\n",
    "    # Configure the LLM using API key from .env\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai_api_key or openai_api_key == \"your_openai_api_key_here\":\n",
    "        print(\"⚠️ Warning: OPENAI_API_KEY not properly set in .env file\")\n",
    "\n",
    "    config_list = [\n",
    "        {\n",
    "            \"model\": \"gpt-4\",\n",
    "            \"api_key\": openai_api_key\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Create AutoGen agents\n",
    "    assistant = autogen.AssistantAgent(\n",
    "        name=\"assistant\",\n",
    "        llm_config={\"config_list\": config_list}\n",
    "    )\n",
    "\n",
    "    user_proxy = autogen.UserProxyAgent(\n",
    "        name=\"user_proxy\",\n",
    "        human_input_mode=\"NEVER\",\n",
    "        max_consecutive_auto_reply=10,\n",
    "        code_execution_config={\"work_dir\": \"coding\"},\n",
    "        function_map={\"brave_search\": query_brave_search}\n",
    "    )\n",
    "\n",
    "    # Start the conversation\n",
    "    user_proxy.initiate_chat(\n",
    "        assistant,\n",
    "        message=f\"Use the brave_search function to find information about: {query}, then summarize the findings.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Demo UI\n",
    "\n",
    "Finally, let's create a demo UI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from IPython.display import HTML, display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create demo UI\n",
    "demo_type = widgets.RadioButtons(\n",
    "    options=['LangChain', 'AutoGen'],\n",
    "    description='Demo Type:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "query_input = widgets.Text(\n",
    "    value='What are the latest developments in quantum computing?',\n",
    "    placeholder='Enter your search query',\n",
    "    description='Query:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(\n",
    "    description='Run Demo',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Click to run the selected demo with your query'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(f\"Running {demo_type.value} demo with query: {query_input.value}\")\n",
    "        if demo_type.value == 'LangChain':\n",
    "            result = run_langchain_demo(query_input.value)\n",
    "            print(f\"\\nResult: {result}\")\n",
    "        else:\n",
    "            run_autogen_demo(query_input.value)\n",
    "\n",
    "run_button.on_click(on_button_click)\n",
    "\n",
    "# Display the UI\n",
    "display(demo_type, query_input, run_button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}