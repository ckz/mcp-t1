{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama-Index with OpenRouter Function Calling Demo\n",
    "\n",
    "This notebook demonstrates how to use llama-index with OpenRouter to create a function calling agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.openrouter import OpenRouter\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENROUTER_API_KEY environment variable is not set\")\n",
    "\n",
    "# Set up a local embedding model (in case we want to use vector embeddings later)\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions\n",
    "\n",
    "Let's define some example functions that our agent can call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for the current weather in a given location.\n",
    "    \n",
    "    Args:\n",
    "        location: The city or location to get weather for\n",
    "        \n",
    "    Returns:\n",
    "        A string describing the weather\n",
    "    \"\"\"\n",
    "    # This is a mock function - in a real application, you would call a weather API\n",
    "    return f\"The weather in {location} is currently sunny with a temperature of 72°F.\"\n",
    "\n",
    "def calculate_mortgage(principal: float, interest_rate: float, years: int) -> str:\n",
    "    \"\"\"\n",
    "    Calculate monthly mortgage payment.\n",
    "    \n",
    "    Args:\n",
    "        principal: The loan amount in dollars\n",
    "        interest_rate: Annual interest rate (as a percentage, e.g., 5.5 for 5.5%)\n",
    "        years: Loan term in years\n",
    "        \n",
    "    Returns:\n",
    "        A string with the monthly payment amount\n",
    "    \"\"\"\n",
    "    monthly_rate = interest_rate / 100 / 12\n",
    "    num_payments = years * 12\n",
    "    monthly_payment = principal * (monthly_rate * (1 + monthly_rate) ** num_payments) / ((1 + monthly_rate) ** num_payments - 1)\n",
    "    return f\"For a ${principal:,.2f} loan with {interest_rate}% interest over {years} years, the monthly payment would be ${monthly_payment:,.2f}\"\n",
    "\n",
    "# Create function tools from our functions\n",
    "weather_tool = FunctionTool.from_defaults(fn=search_weather)\n",
    "mortgage_tool = FunctionTool.from_defaults(fn=calculate_mortgage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize OpenRouter LLM\n",
    "\n",
    "Now let's initialize the OpenRouter LLM and set it as the default for llama-index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenRouter LLM\n",
    "# Using a model that supports function calling\n",
    "llm = OpenRouter(\n",
    "    api_key=api_key,\n",
    "    model=\"anthropic/claude-3-opus-20240229\",  # You can change to another model that supports function calling\n",
    ")\n",
    "\n",
    "# Set the LLM and embedding model as the defaults for llama-index\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a ReAct Agent\n",
    "\n",
    "Let's create a ReAct agent with our tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ReAct agent with our tools\n",
    "agent = ReActAgent.from_tools(\n",
    "    [weather_tool, mortgage_tool],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Agent\n",
    "\n",
    "Now let's test our agent with some example queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step e79ac1f1-1b2a-440a-af61-b4d73fd64b83. Step input: What's the weather in San Francisco?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: search_weather\n",
      "Action Input: {'location': 'San Francisco'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The weather in San Francisco is currently sunny with a temperature of 72°F.\n",
      "\u001b[0m> Running step a1f7769d-3525-4652-add7-5f5edf3fb9bf. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The weather in San Francisco is currently sunny with a temperature of 72°F.\n",
      "\u001b[0mAgent response: The weather in San Francisco is currently sunny with a temperature of 72°F.\n"
     ]
    }
   ],
   "source": [
    "# Test weather query\n",
    "response = agent.chat(\"What's the weather in San Francisco?\")\n",
    "print(f\"Agent response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step c05e536e-b720-4303-af94-481b0917a61c. Step input: Calculate mortgage payment for a $500,000 loan at 4.5% for 30 years\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: calculate_mortgage\n",
      "Action Input: {'principal': 500000, 'interest_rate': 4.5, 'years': 30}\n",
      "\u001b[0m\u001b[1;3;34mObservation: For a $500,000.00 loan with 4.5% interest over 30 years, the monthly payment would be $2,533.43\n",
      "\u001b[0m> Running step e479c718-4191-40c5-8b1d-41ca1f54c51b. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Based on the provided loan details of a $500,000 principal amount, 4.5% annual interest rate, and a 30-year term, your monthly mortgage payment would be $2,533.43. This amount includes both the principal and interest portions of the loan, but does not include property taxes, insurance, or any other fees that may be part of your total monthly payment. Keep in mind that this is just an estimate, and your actual payment may vary slightly depending on the specific terms of your loan and any additional costs.\n",
      "\u001b[0mAgent response: Based on the provided loan details of a $500,000 principal amount, 4.5% annual interest rate, and a 30-year term, your monthly mortgage payment would be $2,533.43. This amount includes both the principal and interest portions of the loan, but does not include property taxes, insurance, or any other fees that may be part of your total monthly payment. Keep in mind that this is just an estimate, and your actual payment may vary slightly depending on the specific terms of your loan and any additional costs.\n"
     ]
    }
   ],
   "source": [
    "# Test mortgage calculation query\n",
    "response = agent.chat(\"Calculate mortgage payment for a $500,000 loan at 4.5% for 30 years\")\n",
    "print(f\"Agent response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Your Own Queries\n",
    "\n",
    "Now you can try your own queries to see how the agent responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 8ab1ff21-fbff-4675-bf1c-02650ea35c42. Step input: What's the weather in Tokyo?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: search_weather\n",
      "Action Input: {'location': 'Tokyo'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The weather in Tokyo is currently sunny with a temperature of 72°F.\n",
      "\u001b[0m> Running step f7888f99-878f-4189-a723-875220b555c4. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The current weather in Tokyo is sunny with a temperature of 72°F.\n",
      "\u001b[0mQuery: What's the weather in Tokyo?\n",
      "Agent response: The current weather in Tokyo is sunny with a temperature of 72°F.\n"
     ]
    }
   ],
   "source": [
    "# Try your own query\n",
    "your_query = \"What's the weather in Tokyo?\"\n",
    "response = agent.chat(your_query)\n",
    "print(f\"Query: {your_query}\")\n",
    "print(f\"Agent response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Retrieval Example\n",
    "\n",
    "Now let's demonstrate how to combine function calling with document retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, Document\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "# Create some sample documents for our knowledge base\n",
    "documents = [\n",
    "    Document(text=\"Python is a high-level, interpreted programming language known for its readability and versatility. It was created by Guido van Rossum and first released in 1991.\"),\n",
    "    Document(text=\"JavaScript is a programming language that is one of the core technologies of the World Wide Web. It was created by Brendan Eich in 1995 while he was working at Netscape Communications Corporation.\"),\n",
    "    Document(text=\"Rust is a multi-paradigm, general-purpose programming language designed for performance and safety, especially safe concurrency. It was created at Mozilla Research by Graydon Hoare in 2010.\"),\n",
    "    Document(text=\"TypeScript is a programming language developed and maintained by Microsoft. It is a strict syntactical superset of JavaScript and adds optional static typing to the language. It was designed by Anders Hejlsberg in 2012.\"),\n",
    "]\n",
    "\n",
    "# Create a vector index from our documents\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Create a query engine from the index\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Create a query engine tool\n",
    "query_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"programming_language_kb\",\n",
    "    description=\"Useful for answering questions about programming languages like Python, JavaScript, Rust, and TypeScript.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new agent with both function tools and the query engine tool\n",
    "combined_agent = ReActAgent.from_tools(\n",
    "    [weather_tool, mortgage_tool, query_tool],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 98a88201-5c51-4ce0-95bf-9c4c184e02e9. Step input: When was Python created and who created it?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: programming_language_kb\n",
      "Action Input: {'input': 'When was Python created and who created it?'}\n",
      "\u001b[1;3;34mObservation: Python was created by Guido van Rossum and first released in 1991.\n",
      "\u001b[0m> Running step 01640514-8b5a-43d6-9371-297976dc442c. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Python was created by Guido van Rossum and first released in 1991.\n",
      "\u001b[0mQuery: When was Python created and who created it?\n",
      "Agent response: Python was created by Guido van Rossum and first released in 1991.\n"
     ]
    }
   ],
   "source": [
    "# Test a query about programming languages\n",
    "programming_query = \"When was Python created and who created it?\"\n",
    "response = combined_agent.chat(programming_query)\n",
    "print(f\"Query: {programming_query}\")\n",
    "print(f\"Agent response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 1c09b75a-c0cb-4263-afe1-c15416e5a876. Step input: What's the weather in New York and when was JavaScript created?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use tools to help me answer the question about the weather in New York and when JavaScript was created.\n",
      "Action: search_weather\n",
      "Action Input: {'location': 'New York'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The weather in New York is currently sunny with a temperature of 72°F.\n",
      "\u001b[0m> Running step a44b43b1-dad6-4194-aecd-749a64be8c68. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have the weather information for New York, but I still need to find out when JavaScript was created. I'll use the programming language knowledge base for that.\n",
      "Action: programming_language_kb\n",
      "Action Input: {'input': 'When was JavaScript created?'}\n",
      "\u001b[1;3;34mObservation: JavaScript was created in 1995 by Brendan Eich while he was working at Netscape Communications Corporation.\n",
      "\u001b[0m> Running step aae57bbd-b467-4e57-b2b8-8c2959c9173d. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The weather in New York is currently sunny with a temperature of 72°F. \n",
      "JavaScript was created in 1995 by Brendan Eich while he was working at Netscape Communications Corporation.\n",
      "\u001b[0mQuery: What's the weather in New York and when was JavaScript created?\n",
      "Agent response: The weather in New York is currently sunny with a temperature of 72°F. \n",
      "JavaScript was created in 1995 by Brendan Eich while he was working at Netscape Communications Corporation.\n"
     ]
    }
   ],
   "source": [
    "# Test a mixed query that requires both knowledge retrieval and function calling\n",
    "mixed_query = \"What's the weather in New York and when was JavaScript created?\"\n",
    "response = combined_agent.chat(mixed_query)\n",
    "print(f\"Query: {mixed_query}\")\n",
    "print(f\"Agent response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to use llama-index with OpenRouter to create a function calling agent and combine it with document retrieval. You can extend this example by adding more functions, using different models, or integrating with other llama-index features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
